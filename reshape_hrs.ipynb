{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from typing import List, Dict\n",
    "from IPython.display import displayimport os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Stata file: /Users/michaelzhu/Desktop/Stanford/CS229/randhrs1992_2020v2_STATA/randhrs1992_2020v2.dta\n",
      "Converting to pickle: /Users/michaelzhu/Desktop/Stanford/CS229/randhrs1992_2020v2_STATA/randhrs1992_2020v2.pkl\n",
      "Conversion complete. File saved as: /Users/michaelzhu/Desktop/Stanford/CS229/randhrs1992_2020v2_STATA/randhrs1992_2020v2.pkl\n"
     ]
    }
   ],
   "source": [
    "def convert_stata_file(input_path, output_format='csv', output_path=None):\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_path}\")\n",
    "        \n",
    "    if output_format.lower() not in ['csv', 'pkl']:\n",
    "        raise ValueError(\"Output format must be 'csv' or 'pkl'\")\n",
    "    \n",
    "    if output_path is None:\n",
    "        base_path = os.path.splitext(input_path)[0]\n",
    "        output_path = f\"{base_path}.{output_format.lower()}\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Reading Stata file: {input_path}\")\n",
    "        df = pd.read_stata(input_path)\n",
    "        \n",
    "        if output_format.lower() == 'csv':\n",
    "            print(f\"Converting to CSV: {output_path}\")\n",
    "            df.to_csv(output_path, index=False)\n",
    "        else:\n",
    "            print(f\"Converting to pickle: {output_path}\")\n",
    "            df.to_pickle(output_path)\n",
    "            \n",
    "        print(f\"Conversion complete. File saved as: {output_path}\")\n",
    "        return output_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during conversion: {str(e)}\")\n",
    "        raise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_stata_file(\n",
    "    input_path=\"randhrs1992_2020v2_STATA/randhrs1992_2020v2.dta\",\n",
    "    output_format=\"pkl\",\n",
    "    output_path=\"randhrs1992_2020v2_STATA/randhrs1992_2020v2.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"randhrs1992_2020v2_STATA/randhrs1992_2020v2.pkl\")\n",
    "print(f\"{len(df)} rows and {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_vars(df: pd.DataFrame, wave: int, prefix: str) -> List[str]:\n",
    "    selected_vars = ['hhidpn', f'inw{wave}']\n",
    "    \n",
    "    all_vars = df.columns.tolist()\n",
    "    \n",
    "    wave_pattern = f\"{prefix}{wave}[A-Za-z]\"\n",
    "    always_pattern = f\"^{prefix}a[A-Za-z]\"\n",
    "    \n",
    "    for var in all_vars:\n",
    "        if re.search(wave_pattern, var) or re.search(always_pattern, var):\n",
    "            selected_vars.append(var)\n",
    "            \n",
    "    return selected_vars\n",
    "\n",
    "def process_wave_data(df: pd.DataFrame, wave: int, prefix: str) -> pd.DataFrame:\n",
    "\n",
    "    selected_vars = get_selected_vars(df, wave, prefix)\n",
    "    \n",
    "    wave_df = df[selected_vars].copy()\n",
    "    wave_df = wave_df[wave_df[f'inw{wave}'] == 1].copy()\n",
    "    \n",
    "    wave_df['wave'] = wave\n",
    "    \n",
    "    rename_dict = {}\n",
    "    for var in selected_vars:\n",
    "        if prefix == 's' and var in [f's{wave}tr20', f's{wave}tr40']:\n",
    "            # Special case for tr20 and tr40\n",
    "            new_name = var.replace(f's{wave}tr', f's{wave}rtr')\n",
    "            rename_dict[var] = new_name\n",
    "            \n",
    "        if var != 'hhidpn' and var != f'inw{wave}':\n",
    "            new_name = var.replace(f'{prefix}{wave}', prefix)\n",
    "            rename_dict[var] = new_name\n",
    "    \n",
    "    wave_df = wave_df.rename(columns=rename_dict)\n",
    "    \n",
    "    # Drop inw column\n",
    "    if prefix in ['r', 'h']:\n",
    "        wave_df = wave_df.drop(columns=[f'inw{wave}'])\n",
    "        \n",
    "    return wave_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs_data = df\n",
    "\n",
    "prefixes = ['s', 'r', 'h']\n",
    "combined_data = {}\n",
    "\n",
    "for prefix in prefixes:\n",
    "    prefix_data = []\n",
    "    for wave in range(1, 16):  \n",
    "        wave_data = process_wave_data(hrs_data, wave, prefix)\n",
    "        prefix_data.append(wave_data)\n",
    "    \n",
    "    combined_data[prefix] = pd.concat(prefix_data, axis=0, ignore_index=True)\n",
    "\n",
    "final_data = combined_data['s']\n",
    "for prefix in ['r', 'h']:\n",
    "    final_data = pd.merge(\n",
    "        final_data, \n",
    "        combined_data[prefix],\n",
    "        on=['hhidpn', 'wave'],\n",
    "        how='inner',\n",
    "        validate='1:1'\n",
    "    )\n",
    "\n",
    "final_data.to_pickle('randhrs1992_2020v2_STATA/randhrs1992_2020v2_long_compact.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
